{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from transformers import TFBertModel, TFBertForSequenceClassification\n",
    "from transformers import glue_convert_examples_to_features\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ŸÜ⁄ØÿßŸá ÿß€åŸÜ ÿ±ŸàÿßŸÜ€å ÿ™€åŸÖÿßÿ±ÿ≥ÿ™ÿßŸÜ€å ⁄©ŸÜ€åÿØ ÿ® ÿ®€å ÿ™€å ÿßÿ≥ ŸÖ€å⁄ØŸá...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÿß€åŸÜ €å⁄©€å ÿπÿ±ÿ®Ÿá ŸÖ€åÿ™ŸàŸÜŸá ÿ≥€åÿ±ÿ¥ ⁄©ŸÜŸá ÿÆÿÆÿÆÿÆ ŸÖŸÜÿ∏Ÿàÿ±ŸÖ ÿ±Ÿà ⁄©Ÿá...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÿØŸàŸÑÿ™€å ⁄©Ÿá ŸÅÿ≥ÿßÿØŸà ÿ±ÿßŸÜÿ™ ÿÆŸàÿßÿ±€å ÿ™ŸÖÿßŸÖÿ¥ ÿ±ÿßŸÅÿ±ÿß⁄Øÿ±ŸÅÿ™Ÿá ÿßÿ≤Ÿà...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  status\n",
       "0  ŸÜ⁄ØÿßŸá ÿß€åŸÜ ÿ±ŸàÿßŸÜ€å ÿ™€åŸÖÿßÿ±ÿ≥ÿ™ÿßŸÜ€å ⁄©ŸÜ€åÿØ ÿ® ÿ®€å ÿ™€å ÿßÿ≥ ŸÖ€å⁄ØŸá...       0\n",
       "1  ÿß€åŸÜ €å⁄©€å ÿπÿ±ÿ®Ÿá ŸÖ€åÿ™ŸàŸÜŸá ÿ≥€åÿ±ÿ¥ ⁄©ŸÜŸá ÿÆÿÆÿÆÿÆ ŸÖŸÜÿ∏Ÿàÿ±ŸÖ ÿ±Ÿà ⁄©Ÿá...       0\n",
       "2  ÿØŸàŸÑÿ™€å ⁄©Ÿá ŸÅÿ≥ÿßÿØŸà ÿ±ÿßŸÜÿ™ ÿÆŸàÿßÿ±€å ÿ™ŸÖÿßŸÖÿ¥ ÿ±ÿßŸÅÿ±ÿß⁄Øÿ±ŸÅÿ™Ÿá ÿßÿ≤Ÿà...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"ready_data.xlsx\", index_col=0)\n",
    "labels = [\"rejected\", \"published\"]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'rejected': 0, 'published': 1}\n",
      "id2label: {0: 'rejected', 1: 'published'}\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "print(f'label2id: {label2id}')\n",
    "print(f'id2label: {id2label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Valid Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15329, 2)\n",
      "(1704, 2)\n",
      "(1893, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.1, random_state=1, stratify=df['status'])\n",
    "train, valid = train_test_split(train, test_size=0.1, random_state=1, stratify=train['status'])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "x_train, y_train = train['comment'].values.tolist(), train['status'].values.tolist()\n",
    "x_valid, y_valid = valid['comment'].values.tolist(), valid['status'].values.tolist()\n",
    "x_test, y_test = test['comment'].values.tolist(), test['status'].values.tolist()\n",
    "\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general config\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "VALID_BATCH_SIZE = 1\n",
    "TEST_BATCH_SIZE = 1\n",
    "\n",
    "EPOCHS = 3\n",
    "EEVERY_EPOCH = 1000\n",
    "LEARNING_RATE = 2e-5\n",
    "CLIP = 0.0\n",
    "\n",
    "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
    "OUTPUT_PATH = './model/bert-fa-base-uncased-sentiment-taaghceh/sample_comments.bin'\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"rejected\",\n",
      "    \"1\": \"published\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"published\": 1,\n",
      "    \"rejected\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 100000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "config = BertConfig.from_pretrained(\n",
    "    MODEL_NAME_OR_PATH, **{\n",
    "        'label2id': label2id,\n",
    "        'id2label': id2label,\n",
    "    })\n",
    "\n",
    "print(config.to_json_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample:\n",
    "    \"\"\" A single example for simple sequence classification. \"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\" Constructs a InputExample. \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def make_examples(tokenizer, x, y=None, maxlen=128, output_mode=\"classification\", is_tf_dataset=True):\n",
    "    examples = []\n",
    "    y = y if isinstance(y, list) or isinstance(y, np.ndarray) else [None] * len(x)\n",
    "\n",
    "    for i, (_x, _y) in enumerate(zip(x, y)):\n",
    "        guid = \"%s\" % i\n",
    "        label = int(_y)\n",
    "        \n",
    "        if isinstance(_x, str):\n",
    "            text_a = _x\n",
    "            text_b = None\n",
    "        else:\n",
    "            assert len(_x) == 2\n",
    "            text_a = _x[0]\n",
    "            text_b = _x[1]\n",
    "        \n",
    "        examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "    \n",
    "    features = glue_convert_examples_to_features(\n",
    "        examples, \n",
    "        tokenizer, \n",
    "        maxlen, \n",
    "        output_mode=output_mode, \n",
    "        label_list=list(np.unique(y)))\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_token_type_ids = []\n",
    "    all_labels = []\n",
    "\n",
    "    for f in features:\n",
    "        if is_tf_dataset:\n",
    "            all_input_ids.append(tf.constant(f.input_ids))\n",
    "            all_attention_masks.append(tf.constant(f.attention_mask))\n",
    "            all_token_type_ids.append(tf.constant(f.token_type_ids))\n",
    "            all_labels.append(tf.constant(f.label))\n",
    "        else:\n",
    "            all_input_ids.append(f.input_ids)\n",
    "            all_attention_masks.append(f.attention_mask)\n",
    "            all_token_type_ids.append(f.token_type_ids)\n",
    "            all_labels.append(f.label)\n",
    "\n",
    "    if is_tf_dataset:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "            'input_ids': all_input_ids,\n",
    "            'attention_mask': all_attention_masks,\n",
    "            'token_type_ids': all_token_type_ids\n",
    "        }, all_labels))\n",
    "\n",
    "        return dataset, features\n",
    "    \n",
    "    xdata = [np.array(all_input_ids), np.array(all_attention_masks), np.array(all_token_type_ids)]\n",
    "    ydata = all_labels\n",
    "\n",
    "    return [xdata, ydata], features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/transformers/data/processors/glue.py:66: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_base, train_examples = make_examples(tokenizer, x_train, y_train, maxlen=128)\n",
    "valid_dataset_base, valid_examples = make_examples(tokenizer, x_valid, y_valid, maxlen=128)\n",
    "\n",
    "test_dataset_base, test_examples = make_examples(tokenizer, x_test, y_test, maxlen=128)\n",
    "[xtest, ytest], test_examples = make_examples(tokenizer, x_test, y_test, maxlen=128, is_tf_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     input_ids: [    2  8969  3274  5899 34634  4241  4338  1379  3826  3125  3556  3486\n",
      "  3274  3660  6853  7693 66773  4313 32196 10652 14114     4     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "attention_mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "token_type_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "        target: 0\n"
     ]
    }
   ],
   "source": [
    "for value in train_dataset_base.take(1):\n",
    "    print(f'     input_ids: {value[0][\"input_ids\"]}')\n",
    "    print(f'attention_mask: {value[0][\"attention_mask\"]}')\n",
    "    print(f'token_type_ids: {value[0][\"token_type_ids\"]}')\n",
    "    print(f'        target: {value[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_dataset(dataset, batch_size):\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(dataset, batch_size):\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15329, 1704)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = get_training_dataset(train_dataset_base, TRAIN_BATCH_SIZE)\n",
    "valid_dataset = get_training_dataset(valid_dataset_base, VALID_BATCH_SIZE)\n",
    "\n",
    "train_steps = len(train_examples) // TRAIN_BATCH_SIZE\n",
    "valid_steps = len(valid_examples) // VALID_BATCH_SIZE\n",
    "\n",
    "train_steps, valid_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_name, config, learning_rate=3e-5):\n",
    "    model = TFBertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at /home/reza/Desktop/aasaam/comment-classification/comment_classification/R&D/model/tf_model.h5 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME_OR_PATH = \"/home/reza/Desktop/aasaam/comment-classification/comment_classification/R&D/model/tf_model.h5\"\n",
    "model = build_model(MODEL_NAME_OR_PATH, config, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Adam/Adam/update/mul_1' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_25497/398553755.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', \"r = model.fit(\\n    train_dataset,\\n    validation_data=valid_dataset,\\n    steps_per_epoch=train_steps,\\n    validation_steps=valid_steps,\\n    epochs=EPOCHS,\\n    verbose=1)\\n\\nfinal_accuracy = r.history['val_accuracy']\\nprint('FINAL ACCURACY MEAN: ', np.mean(final_accuracy))\\n\")\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2358, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/magics/execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 1, in <module>\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/transformers/modeling_tf_utils.py\", line 1154, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 539, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 678, in apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 723, in _distributed_apply\n      update_op = distribution.extended.update(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 701, in apply_grad_to_update_var\n      return self._resource_apply_sparse_duplicate_indices(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 1326, in _resource_apply_sparse_duplicate_indices\n      return self._resource_apply_sparse(summed_grad, handle, unique_indices,\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py\", line 206, in _resource_apply_sparse\n      m_t = tf.compat.v1.assign(m, m * coefficients['beta_1_t'],\nNode: 'Adam/Adam/update/mul_1'\nfailed to allocate memory\n\t [[{{node Adam/Adam/update/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_100016]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'Adam/Adam/update/mul_1' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_25497/398553755.py\", line 1, in <cell line: 1>\n      get_ipython().run_cell_magic('time', '', \"r = model.fit(\\n    train_dataset,\\n    validation_data=valid_dataset,\\n    steps_per_epoch=train_steps,\\n    validation_steps=valid_steps,\\n    epochs=EPOCHS,\\n    verbose=1)\\n\\nfinal_accuracy = r.history['val_accuracy']\\nprint('FINAL ACCURACY MEAN: ', np.mean(final_accuracy))\\n\")\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2358, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/IPython/core/magics/execution.py\", line 1316, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 1, in <module>\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/transformers/modeling_tf_utils.py\", line 1154, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 539, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 678, in apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 723, in _distributed_apply\n      update_op = distribution.extended.update(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 701, in apply_grad_to_update_var\n      return self._resource_apply_sparse_duplicate_indices(\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\", line 1326, in _resource_apply_sparse_duplicate_indices\n      return self._resource_apply_sparse(summed_grad, handle, unique_indices,\n    File \"/home/reza/Desktop/aasaam/comment-classification/.venv/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py\", line 206, in _resource_apply_sparse\n      m_t = tf.compat.v1.assign(m, m * coefficients['beta_1_t'],\nNode: 'Adam/Adam/update/mul_1'\nfailed to allocate memory\n\t [[{{node Adam/Adam/update/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_100016]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=valid_steps,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1)\n",
    "\n",
    "final_accuracy = r.history['val_accuracy']\n",
    "print('FINAL ACCURACY MEAN: ', np.mean(final_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save_pretrained(os.path.dirname(OUTPUT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation / Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 128s 1s/step - loss: 0.8027 - accuracy: 0.7485\n",
      "\n",
      "Evaluation: [0.8027344346046448, 0.7485472559928894]\n",
      "\n",
      "60/60 [==============================] - 126s 2s/step\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    rejected       0.76      0.73      0.74       946\n",
      "   published       0.74      0.77      0.75       947\n",
      "\n",
      "    accuracy                           0.75      1893\n",
      "   macro avg       0.75      0.75      0.75      1893\n",
      "weighted avg       0.75      0.75      0.75      1893\n",
      "\n",
      "\n",
      "F1: 0.7484204859467789\n"
     ]
    }
   ],
   "source": [
    "ev = model.evaluate(test_dataset_base.batch(TEST_BATCH_SIZE))\n",
    "print()\n",
    "print(f'Evaluation: {ev}')\n",
    "print()\n",
    "\n",
    "predictions = model.predict(xtest)\n",
    "ypred = predictions[0].argmax(axis=-1).tolist()\n",
    "\n",
    "print()\n",
    "print(classification_report(ytest, ypred, target_names=labels))\n",
    "print()\n",
    "\n",
    "print(f'F1: {f1_score(ytest, ypred, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPositive\tNegative\n",
      "Positive\tTP=730\t\tFP=259\n",
      "Negetive\tFN=217\t\tTN=687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(ytest, ypred).ravel()\n",
    "print(\"\\t\\tPositive\\tNegative\")\n",
    "print(f\"Positive\\tTP={tp}\\t\\tFP={fp}\")\n",
    "print(f\"Negetive\\tFN={fn}\\t\\tTN={tn}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('comment-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08b54b589637f87373e8394536c11cb44a56dcb99faa188bb705919399e0b2bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
